import os
from typing import Dict, Optional, Union

from autogen import GroupChat, GroupChatManager
from autogen.coding.jupyter import JupyterCodeExecutor
from autogen.coding.jupyter import JupyterConnectionInfo
from autogen import Agent, ConversableAgent

import chainlit as cl
from chainlit.types import ThreadDict

start_system_message = "ä½ å¥½ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ çš„éœ€æ±‚ã€‚æˆ‘ä¼šå¸®ä½ è§„åˆ’å¹¶æ‰§è¡Œã€‚"

admin_prompt="""
ç®¡ç†å‘˜ã€‚ä¸è§„åˆ’å¸ˆäº¤æµè®¨è®ºè®¡åˆ’ã€‚è®¡åˆ’æ‰§è¡Œéœ€è¦å¾—åˆ°ç®¡ç†å‘˜çš„æ‰¹å‡†ã€‚
"""

planner_prompt="""
è§„åˆ’å¸ˆã€‚æå‡ºä¸€ä¸ªè®¡åˆ’ã€‚æ ¹æ®ç®¡ç†å‘˜å’Œåé¦ˆä¿®æ”¹è®¡åˆ’ï¼Œç›´åˆ°ç®¡ç†å‘˜æ‰¹å‡†ã€‚
è®¡åˆ’å¯èƒ½æ¶‰åŠä¸€ä¸ªä¼šå†™ä»£ç çš„å·¥ç¨‹å¸ˆå’Œä¸€ä¸ªä¸ä¼šå†™ä»£ç çš„ç§‘å­¦å®¶ã€‚
é¦–å…ˆè§£é‡Šè®¡åˆ’ã€‚æ¸…æ¥šåœ°è¯´æ˜å“ªä¸ªæ­¥éª¤ç”±å·¥ç¨‹å¸ˆæ‰§è¡Œï¼Œå“ªä¸ªæ­¥éª¤ç”±ç§‘å­¦å®¶æ‰§è¡Œã€‚
"""

engineer_prompt="""
å·¥ç¨‹å¸ˆã€‚ä½ æŒ‰ç…§æ‰¹å‡†çš„è®¡åˆ’è¡ŒåŠ¨ã€‚ä½ ç¼–å†™ Python/Shell ä»£ç æ¥è§£å†³ä»»åŠ¡ã€‚å°†ä»£ç æ”¾åœ¨ä»£ç å—ä¸­ï¼ŒæŒ‡å®šè„šæœ¬ç±»å‹ã€‚ç”¨æˆ·æ— æ³•ä¿®æ”¹ä½ çš„ä»£ç ã€‚å› æ­¤ï¼Œä¸è¦æä¾›éœ€è¦å…¶ä»–äººä¿®æ”¹çš„ä¸å®Œæ•´ä»£ç ã€‚å¦‚æœä¸æ‰“ç®—ç”±æ‰§è¡Œè€…æ‰§è¡Œï¼Œè¯·ä¸è¦ä½¿ç”¨ä»£ç å—ã€‚
ä¸€ä¸ªå›å¤ä¸­ä¸è¦åŒ…å«å¤šä¸ªä»£ç å—ã€‚ä¸è¦è¦æ±‚å…¶ä»–äººå¤åˆ¶ç²˜è´´ç»“æœã€‚æ£€æŸ¥æ‰§è¡Œè€…è¿”å›çš„æ‰§è¡Œç»“æœã€‚
å¦‚æœç»“æœè¡¨æ˜æœ‰é”™è¯¯ï¼Œè¯·ä¿®å¤é”™è¯¯å¹¶é‡æ–°è¾“å‡ºä»£ç ã€‚å»ºè®®æä¾›å®Œæ•´çš„ä»£ç è€Œä¸æ˜¯éƒ¨åˆ†ä»£ç æˆ–ä»£ç æ›´æ”¹ã€‚å¦‚æœé”™è¯¯æ— æ³•ä¿®å¤ï¼Œæˆ–è€…å³ä½¿æˆåŠŸæ‰§è¡Œä»£ç åä»»åŠ¡ä»æœªè§£å†³ï¼Œè¯·åˆ†æé—®é¢˜ï¼Œé‡æ–°å®¡è§†å‡è®¾ï¼Œæ”¶é›†æ‰€éœ€çš„é¢å¤–ä¿¡æ¯ï¼Œå¹¶è€ƒè™‘å°è¯•ä¸åŒçš„æ–¹æ³•ã€‚
ä¸è¦å°†ç¨‹åºè¿è¡Œç»“æœå†™æ–‡ä»¶ä¸­ã€‚è¦å°†ç»“æœé€šè¿‡printå‡½æ•°æ‰“å°å‡ºæ¥ã€‚
"""
scientist_prompt="""
ç§‘å­¦å®¶ã€‚ä½ æŒ‰ç…§æ‰¹å‡†çš„è®¡åˆ’è¡ŒåŠ¨ã€‚ä½ èƒ½å¤Ÿå¯¹æ‰§è¡Œç»“æœè¿›è¡Œæ•°æ®åˆ†æã€‚ä½ ä¸ä¼šå†™ä»£ç ã€‚
"""
executor_prompt="""
æ‰§è¡Œè€…ã€‚æ‰§è¡Œå·¥ç¨‹å¸ˆç¼–å†™çš„ä»£ç ã€‚
"""

chat_llm_config = {
    "config_list": [{
        "model": "deepseek-chat",
        "api_type": "openai",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "base_url": os.getenv("OPENAI_BASE_URL"),
    }],
    "temperature": 1,
    "cache_seed": None
}

coder_llm_config = {
    "config_list": [{
        "model": "deepseek-coder",
        "api_type": "openai",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "base_url": os.getenv("OPENAI_BASE_URL"),
    }],
    "temperature": 1,
    "cache_seed": None
}

os.makedirs(".coding", exist_ok=True)

class ChainlitConversableAgent(ConversableAgent):
    def get_human_input(self, prompt: str) -> str:
        if self.name == "Admin":
            response = cl.run_sync(cl.AskActionMessage(
                author=self.name,
                content=f"ç»§ç»­è¿è¡Œæˆ–æä¾›åé¦ˆå¸®åŠ©{self.name}ï¼Ÿ",
                actions=[
                    cl.Action(
                        name="feedback",
                        value="feedback",
                        label="ğŸ’¬ ç»™äºˆå»ºè®®",
                    ),
                    cl.Action(
                        name="exit",
                        value="exit",
                        label="ğŸ”š é€€å‡º"
                    ),
                ],
                timeout=300
            ).send())
        else:
            response = cl.run_sync(cl.AskActionMessage(
                author=self.name,
                content=f"ç»§ç»­è¿è¡Œæˆ–æä¾›åé¦ˆå¸®åŠ©{self.name}ï¼Ÿ",
                actions=[
                    cl.Action(
                        name="continue", 
                        value="continue", 
                        label="âœ… ç»§ç»­è¿è¡Œ"
                    ),
                    cl.Action(
                        name="feedback",
                        value="feedback",
                        label="ğŸ’¬ ç»™äºˆå»ºè®®",
                    ),
                ],
                timeout=300
            ).send())
    
        if response:
            if response.get("value") == "continue":
                return ""
            if response.get("value") == "exit":
                print("exit")
                return "exit"
            if response.get("value") == "feedback":
                feedback = cl.run_sync(cl.AskUserMessage(
                    author=self.name,
                    content="ä¸ºAutogen-Agentç»™äºˆè¿è¡Œå»ºè®®:",
                    timeout=300
                ).send())
                feedback_output = str(feedback['output'])
                if feedback_output:
                    cl.run_sync(cl.Message.from_dict(
                        feedback
                    ).remove())
                    return feedback_output
        return "exit"
    
    def send(
        self,
        message: Union[Dict, str],
        recipient: Agent,
        request_reply: Optional[bool] = None,
        silent: Optional[bool] = False,
    ):
        content = message if isinstance(message, str) else message['content']
        cl.run_sync(cl.Message(author=self.name,content=content).send())
        super(ChainlitConversableAgent, self).send(
            message=content,
            recipient=recipient,
            request_reply=request_reply,
            silent=silent,
        )


class AutoGenAgent():
    def __init__(self) -> None:
        pass


    def state_transition(self, last_speaker, groupchat):
        select = cl.run_sync(
             cl.AskActionMessage(
                 author="Chat Agent",
                  content="è¯·é—®ä¸‹ä¸€æ­¥ç”±è°æ‰§è¡Œï¼Ÿ",
                  actions=[
                    cl.Action(
                        name="Planner", 
                        value="Planner", 
                        label="ğŸ“ è§„åˆ’å¸ˆ"
                    ),
                    cl.Action(
                        name="Engineer",
                        value="Engineer",
                        label="ğŸ› ï¸ å·¥ç¨‹å¸ˆ",
                    ),
                    cl.Action(
                        name="Scientist",
                        value="Scientist",
                        label="ğŸ”¬ ç§‘å­¦å®¶"
                    ),
                    cl.Action(
                        name="Executor",
                        value="Executor",
                        label="ğŸš€ æ‰§è¡Œè€…"
                    ),
                    cl.Action(
                        name="Admin",
                        value="Admin",
                        label="ğŸ§‘â€ğŸ’¼ ç®¡ç†å‘˜"
                    )
                ],
                timeout=300
            ).send()
        )
        if select:
            if select.get("value") == "Planner":
                return cl.user_session.get("planner")
            if select.get("value") == "Engineer":
                return cl.user_session.get("engineer")
            if select.get("value") == "Scientist":
                return cl.user_session.get("scientist")
            if select.get("value") == "Executor":
                return cl.user_session.get("executor")
            return cl.user_session.get("admin")
            
        
    async def settings(self):
            pass

    async def message(self, message: cl.Message):
        manager: GroupChatManager = cl.user_session.get("manager")
        manager.initiate_chat(
            manager,
            message=message.content,
        )
            
    async def resume(self, thread: ThreadDict):
        pass

    async def start(self):
        jupyter = JupyterCodeExecutor(
            jupyter_server = JupyterConnectionInfo(
                host=str(os.getenv("JUPYTER_SERVER").split(":")[0]),
                port=int(os.getenv("JUPYTER_SERVER").split(":")[1]),
                token=os.getenv("JUPYTER_TOKEN"),
                use_https=False
            ),
            output_dir=".coding"
        )
        cl.user_session.set("jupyter", jupyter)
        print("start jupyter kernel " + jupyter._kernel_id)

        planner = ChainlitConversableAgent(
            "Planner", 
            human_input_mode="NEVER",
            llm_config=chat_llm_config,
            system_message=planner_prompt,
        )
        cl.user_session.set("planner", planner)
        admin = ChainlitConversableAgent(
            "Admin",
            human_input_mode="ALWAYS",
            system_message=admin_prompt,
        )
        cl.user_session.set("admin", admin)
        engineer = ChainlitConversableAgent(
            "Engineer",
            human_input_mode="ALWAYS",
            llm_config=coder_llm_config,
            system_message=engineer_prompt,
        )
        cl.user_session.set("engineer", engineer)
        scientist = ChainlitConversableAgent(
            "Scientist",
            human_input_mode="ALWAYS",
            llm_config=coder_llm_config,
            system_message=scientist_prompt,
        )
        cl.user_session.set("scientist", scientist)
        executor = ChainlitConversableAgent(
            "Executor",
            human_input_mode="NEVER",
            code_execution_config={
                "last_n_messages": 3,
                "executor": jupyter
            },
        )
        cl.user_session.set("executor", executor)
        groupchat = GroupChat(
            agents=[admin, planner, engineer, executor, scientist],
            messages=[], max_round=20,
            speaker_selection_method=self.state_transition,
        )
        manager = GroupChatManager(groupchat=groupchat, llm_config=chat_llm_config)

        cl.user_session.set("manager",manager)

        await cl.Message(
            author="Chat Agent",content=start_system_message
        ).send()

    async def end(self):
        jupyter: JupyterCodeExecutor = cl.user_session.get("jupyter")
        jupyter.stop()
        print("stop jupyter kernel " + jupyter._kernel_id)

import os
from typing import Dict, Optional, Union

from autogen import GroupChat, GroupChatManager
from autogen.coding.jupyter import JupyterCodeExecutor
from autogen.coding.jupyter import JupyterConnectionInfo
from autogen import Agent, ConversableAgent

import chainlit as cl
from chainlit.types import ThreadDict

from .base import BaseModel

start_system_message = "ä½ å¥½ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ çš„éœ€æ±‚ã€‚æˆ‘ä¼šå¸®ä½ è§„åˆ’å¹¶æ‰§è¡Œã€‚"

admin_prompt="""
ç®¡ç†å‘˜ã€‚ä¸è§„åˆ’å¸ˆäº¤æµè®¨è®ºè®¡åˆ’ã€‚è®¡åˆ’æ‰§è¡Œéœ€è¦å¾—åˆ°ç®¡ç†å‘˜çš„æ‰¹å‡†ã€‚
"""

planner_prompt="""
è§„åˆ’å¸ˆã€‚æå‡ºä¸€ä¸ªè®¡åˆ’ã€‚æ ¹æ®ç®¡ç†å‘˜å’Œåé¦ˆä¿®æ”¹è®¡åˆ’ï¼Œç›´åˆ°ç®¡ç†å‘˜æ‰¹å‡†ã€‚
è®¡åˆ’å¯èƒ½æ¶‰åŠä¸€ä¸ªä¼šå†™ä»£ç çš„å·¥ç¨‹å¸ˆå’Œä¸€ä¸ªä¸ä¼šå†™ä»£ç çš„ç§‘å­¦å®¶ã€‚
é¦–å…ˆè§£é‡Šè®¡åˆ’ã€‚æ¸…æ¥šåœ°è¯´æ˜å“ªä¸ªæ­¥éª¤ç”±å·¥ç¨‹å¸ˆæ‰§è¡Œï¼Œå“ªä¸ªæ­¥éª¤ç”±ç§‘å­¦å®¶æ‰§è¡Œã€‚
"""

engineer_prompt="""
å·¥ç¨‹å¸ˆã€‚ä½ æŒ‰ç…§æ‰¹å‡†çš„è®¡åˆ’è¡ŒåŠ¨ã€‚ä½ ç¼–å†™ Python/Shell ä»£ç æ¥è§£å†³ä»»åŠ¡ã€‚å°†ä»£ç æ”¾åœ¨ä»£ç å—ä¸­ï¼ŒæŒ‡å®šè„šæœ¬ç±»å‹ã€‚ç”¨æˆ·æ— æ³•ä¿®æ”¹ä½ çš„ä»£ç ã€‚å› æ­¤ï¼Œä¸è¦æä¾›éœ€è¦å…¶ä»–äººä¿®æ”¹çš„ä¸å®Œæ•´ä»£ç ã€‚å¦‚æœä¸æ‰“ç®—ç”±æ‰§è¡Œè€…æ‰§è¡Œï¼Œè¯·ä¸è¦ä½¿ç”¨ä»£ç å—ã€‚
ä¸€ä¸ªå›å¤ä¸­ä¸è¦åŒ…å«å¤šä¸ªä»£ç å—ã€‚ä¸è¦è¦æ±‚å…¶ä»–äººå¤åˆ¶ç²˜è´´ç»“æœã€‚æ£€æŸ¥æ‰§è¡Œè€…è¿”å›çš„æ‰§è¡Œç»“æœã€‚
å¦‚æœç»“æœè¡¨æ˜æœ‰é”™è¯¯ï¼Œè¯·ä¿®å¤é”™è¯¯å¹¶é‡æ–°è¾“å‡ºä»£ç ã€‚å»ºè®®æä¾›å®Œæ•´çš„ä»£ç è€Œä¸æ˜¯éƒ¨åˆ†ä»£ç æˆ–ä»£ç æ›´æ”¹ã€‚å¦‚æœé”™è¯¯æ— æ³•ä¿®å¤ï¼Œæˆ–è€…å³ä½¿æˆåŠŸæ‰§è¡Œä»£ç åä»»åŠ¡ä»æœªè§£å†³ï¼Œè¯·åˆ†æé—®é¢˜ï¼Œé‡æ–°å®¡è§†å‡è®¾ï¼Œæ”¶é›†æ‰€éœ€çš„é¢å¤–ä¿¡æ¯ï¼Œå¹¶è€ƒè™‘å°è¯•ä¸åŒçš„æ–¹æ³•ã€‚
ä¸è¦å°†ç¨‹åºè¿è¡Œç»“æœå†™æ–‡ä»¶ä¸­ã€‚è¦å°†ç»“æœé€šè¿‡printå‡½æ•°æ‰“å°å‡ºæ¥ã€‚
"""
scientist_prompt="""
ç§‘å­¦å®¶ã€‚ä½ æŒ‰ç…§æ‰¹å‡†çš„è®¡åˆ’è¡ŒåŠ¨ã€‚ä½ èƒ½å¤Ÿå¯¹æ‰§è¡Œç»“æœè¿›è¡Œæ•°æ®åˆ†æã€‚ä½ ä¸ä¼šå†™ä»£ç ã€‚
"""
executor_prompt="""
æ‰§è¡Œè€…ã€‚æ‰§è¡Œå·¥ç¨‹å¸ˆç¼–å†™çš„ä»£ç ã€‚
"""

chat_llm_config = {
    "config_list": [{
        "model": "deepseek-chat",
        "api_type": "openai",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "base_url": os.getenv("OPENAI_BASE_URL"),
    }],
    "temperature": 1,
    "cache_seed": None
}

coder_llm_config = {
    "config_list": [{
        "model": "deepseek-coder",
        "api_type": "openai",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "base_url": os.getenv("OPENAI_BASE_URL"),
    }],
    "temperature": 1,
    "cache_seed": None
}

class ChainlitConversableAgent(ConversableAgent):
    def get_human_input(self, prompt: str) -> str:
        response = cl.run_sync(cl.AskActionMessage(
            content="ç»§ç»­è¿è¡Œæˆ–æä¾›åé¦ˆå¸®åŠ©Agentï¼Ÿ",
            actions=[
                cl.Action(
                    name="continue", 
                    value="continue", 
                    label="âœ… ç»§ç»­è¿è¡Œ"
                ),
                cl.Action(
                    name="feedback",
                    value="feedback",
                    label="ğŸ’¬ ç»™äºˆå»ºè®®",
                ),
                cl.Action(
                    name="exit",
                    value="exit",
                    label="ğŸ”š é€€å‡º"
                ),
            ],
            timeout=300
        ).send())
    
        if response:
            if response.get("value") == "continue":
                return ""
            if response.get("value") == "exit":
                return "exit"
            if response.get("value") == "feedback":
                feedback = cl.run_sync(cl.AskUserMessage(
                    content="ä¸ºAutogen-Agentç»™äºˆè¿è¡Œå»ºè®®:",
                    timeout=300
                ).send())
                feedback_output = str(feedback['output'])
                if feedback_output:
                    cl.run_sync(cl.Message.from_dict(
                        feedback
                    ).remove())
                    return feedback_output
        return "exit"
    
    def send(
        self,
        message: Union[Dict, str],
        recipient: Agent,
        request_reply: Optional[bool] = None,
        silent: Optional[bool] = False,
    ):
        content = message if isinstance(message, str) else message['content']
        cl.run_sync(cl.Message(content=content).send())
        super(ChainlitConversableAgent, self).send(
            message=content,
            recipient=recipient,
            request_reply=request_reply,
            silent=silent,
        )


class AutoGenAgent(BaseModel):
    def __init__(self) -> None:
        self.jupyter = JupyterCodeExecutor(
            jupyter_server = JupyterConnectionInfo(
                host=str(os.getenv("JUPYTER_SERVER").split(":")[0]),
                port=int(os.getenv("JUPYTER_SERVER").split(":")[1]),
                token=os.getenv("JUPYTER_TOKEN"),
                use_https=False
            )
        )
        self.planner = ChainlitConversableAgent(
            "Planner", 
            human_input_mode="NEVER",
            llm_config=chat_llm_config,
            system_message=planner_prompt,
        )
        self.admin = ChainlitConversableAgent(
            "Admin",
            human_input_mode="ALWAYS",
            system_message=admin_prompt,
        )
        self.engineer = ChainlitConversableAgent(
            "Engineer",
            human_input_mode="ALWAYS",
            llm_config=coder_llm_config,
            system_message=engineer_prompt,
        )
        self.scientist = ChainlitConversableAgent(
            "Scientist",
            human_input_mode="ALWAYS",
            llm_config=coder_llm_config,
            system_message=scientist_prompt,
        )
        self.executor = ChainlitConversableAgent(
            "Executor",
            human_input_mode="NEVER",
            code_execution_config={
                "last_n_messages": 3,
                "executor": self.jupyter
            },
        )
        self.groupchat = GroupChat(
            agents=[self.admin, self.planner, self.engineer, self.executor, self.scientist],
            messages=[], max_round=20,
            speaker_selection_method=self.state_transition,
        )
        self.manager = GroupChatManager(groupchat=self.groupchat, llm_config=chat_llm_config)

    def state_transition(self, last_speaker, groupchat):
        select = cl.run_sync(
             cl.AskActionMessage(
                  content="è¯·é—®ä¸‹ä¸€æ­¥ç”±è°æ‰§è¡Œï¼Ÿ",
                  actions=[
                    cl.Action(
                        name="Planner", 
                        value="Planner", 
                        label="ğŸ“ è§„åˆ’å¸ˆ"
                    ),
                    cl.Action(
                        name="Engineer",
                        value="Engineer",
                        label="ğŸ› ï¸ å·¥ç¨‹å¸ˆ",
                    ),
                    cl.Action(
                        name="Scientist",
                        value="Scientist",
                        label="ğŸ”¬ ç§‘å­¦å®¶"
                    ),
                    cl.Action(
                        name="Executor",
                        value="Executor",
                        label="ğŸš€ æ‰§è¡Œè€…"
                    ),
                    cl.Action(
                        name="Admin",
                        value="Admin",
                        label="ğŸ§‘â€ğŸ’¼ ç®¡ç†å‘˜"
                    )
                ],
            ).send()
        )
        if select:
            if select.get("value") == "Planner":
                return self.planner
            if select.get("value") == "Engineer":
                return self.engineer
            if select.get("value") == "Scientist":
                return self.scientist
            if select.get("value") == "Executor":
                return self.executor
            return self.admin
            
        
    async def settings(self):
            pass

    async def message(self, message: cl.Message):
        runable = cl.user_session.get("runable")
        if runable:
            self.admin.initiate_chat(
                self.manager,
                message=message.content
            )
            
    async def resume(self, thread: ThreadDict):
        pass

    async def start(self):
        await cl.Message(
            author="Chat Agent",content=start_system_message
        ).send()
        cl.user_session.set("runable", True)

    async def end(self):
        self.jupyter.stop()
        pass
